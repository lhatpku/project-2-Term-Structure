{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: monthdelta in /anaconda3/lib/python3.7/site-packages (0.9.1)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install monthdelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Package\n",
    "import bs4 as bs\n",
    "import urllib.request\n",
    "import pandas as pd\n",
    "import time\n",
    "import datetime\n",
    "import monthdelta\n",
    "from config import sql_Password\n",
    "from sqlalchemy import create_engine, Column, Integer, String, Float, Date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chrome Driver\n",
    "# executable_path = {'executable_path':'/usr/local/bin/chromedriver'}\n",
    "# browser = Browser('chrome',**executable_path,headless=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web Scraping Yahoo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Web Scraping Function\n",
    "* Input: \n",
    "    * a) Ticker Name, \n",
    "    * b) Start date, in datetime format; \n",
    "    * c) End date, in datetime format; \n",
    "    * d) Optional, data frequency:\n",
    "        * d.1) 1d (every business day); \n",
    "        * d.2) 1wk (every week); \n",
    "        * d.3) 1mo (every month)\n",
    "* Output: Dataframe with the following column names:\n",
    "    * 1) Open Price\n",
    "    * 2) High Price\n",
    "    * 3) Low Price\n",
    "    * 4) Close Price\n",
    "    * 5) Adj Close Price\n",
    "    * 6) Volume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_historical_price(ticker, date1, date2, frequency='1d',display=True):\n",
    " \n",
    "    format_string='%Y-%m-%d %H:%M:%S'\n",
    " \n",
    "    # One day (86400 second) adjustment required to get dates printed to match web site manual output\n",
    "    _date1 = date1.strftime(\"%Y-%m-%d 00:00:00\")\n",
    "    date1_epoch = str(int(time.mktime(time.strptime(_date1, format_string)))- 86400)\n",
    "    \n",
    "    if display == True: \n",
    "        print(\"\")\n",
    "        print(date1, date1_epoch, \" + 86,400 = \", str(int(date1_epoch) + 86400))\n",
    " \n",
    "    _date2 = date2.strftime(\"%Y-%m-%d 00:00:00\")\n",
    "    date2_epoch = str(int(time.mktime(time.strptime(_date2, format_string))))\n",
    "    \n",
    "    if display == True:\n",
    "        print(date2, date2_epoch)\n",
    " \n",
    "    url = 'https://finance.yahoo.com/quote/' + ticker + '/history?period1=' + date1_epoch + '&period2=' + date2_epoch + '&interval='+frequency+'&filter=history&frequency='+frequency\n",
    "    source = urllib.request.urlopen(url).read()      \n",
    "    soup = bs.BeautifulSoup(source,'lxml')\n",
    "    table_rows = soup.find_all('tr')\n",
    "      \n",
    "    extract_table = []\n",
    "      \n",
    "    for table_row in table_rows:\n",
    "        table_row_values = table_row.find_all('td')\n",
    "        extract_row = [i.text for i in table_row_values]\n",
    "        extract_table.append(extract_row)        \n",
    "      \n",
    "    column_names = ['Date', 'Open', 'High', 'Low', 'Close', 'Adj Close', 'Volume']\n",
    "  \n",
    "    #extract_table = extract_table[1:-2]\n",
    "    extract_table_df = pd.DataFrame(extract_table)\n",
    "    extract_table_df.columns = column_names\n",
    "    extract_table_df.set_index(column_names[0], inplace=True)\n",
    "    extract_table_df = extract_table_df.convert_objects(convert_numeric=True)\n",
    "    extract_table_df = extract_table_df.iloc[::-1]\n",
    "    extract_table_df.dropna(inplace=True)\n",
    "      \n",
    "    return extract_table_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Web Scraping Function Trial with Apple Stock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Today     : 2019-02-22\n",
      "Start Date: 2018-06-02 Start Date Epoch: 1527915600\n",
      "End   Date: 2019-02-19 End   Date Epoch: 1550556000\n",
      "Processing 2018-06-02 thru 2018-07-31.\n",
      "\n",
      "2018-06-02 1527829200  + 86,400 =  1527915600\n",
      "2018-07-31 1533013200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:37: FutureWarning: convert_objects is deprecated.  To re-infer data dtypes for object columns, use DataFrame.infer_objects()\n",
      "For all other conversions use the data-type specific converters pd.to_datetime, pd.to_timedelta and pd.to_numeric.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 2018-08-01 thru 2018-09-30.\n",
      "\n",
      "2018-08-01 1533013200  + 86,400 =  1533099600\n",
      "2018-09-30 1538283600\n",
      "Processing 2018-10-01 thru 2018-11-30.\n",
      "\n",
      "2018-10-01 1538283600  + 86,400 =  1538370000\n",
      "2018-11-30 1543557600\n",
      "Processing 2018-12-01 thru 2019-01-31.\n",
      "\n",
      "2018-12-01 1543557600  + 86,400 =  1543644000\n",
      "2019-01-31 1548914400\n",
      "Processing 2019-02-01 thru 2019-02-19.\n",
      "\n",
      "2019-02-01 1548914400  + 86,400 =  1549000800\n",
      "2019-02-19 1550556000\n",
      "                Open    High     Low   Close  Adj Close      Volume\n",
      "Date                                                               \n",
      "Jun 01, 2018  187.99  190.26  187.75  190.24     188.11  23,442,500\n",
      "Jun 04, 2018  191.64  193.42  191.35  191.83     189.68  26,266,200\n",
      "Jun 05, 2018  193.07  193.94  192.36  193.31     191.14  21,566,000\n",
      "Jun 06, 2018  193.63  194.08  191.92  193.98     191.81  20,933,600\n",
      "Jun 07, 2018  194.14  194.20  192.34  193.46     191.29  21,347,200\n",
      "Jun 08, 2018  191.17  192.00  189.77  191.70     189.55  26,656,800\n",
      "Jun 11, 2018  191.35  191.97  190.21  191.23     189.09  18,308,500\n",
      "Jun 12, 2018  191.39  192.61  191.15  192.28     190.13  16,911,100\n",
      "Jun 13, 2018  192.42  192.88  190.44  190.70     188.56  21,638,400\n",
      "Jun 14, 2018  191.55  191.57  190.22  190.80     188.66  21,610,100\n",
      "Jun 15, 2018  190.03  190.16  188.26  188.84     186.72  61,719,200\n",
      "Jun 18, 2018  187.88  189.22  187.20  188.74     186.63  18,484,900\n",
      "Jun 19, 2018  185.14  186.33  183.45  185.69     183.61  33,578,500\n",
      "Jun 20, 2018  186.35  187.20  185.73  186.50     184.41  20,628,700\n",
      "Jun 21, 2018  187.25  188.35  184.94  185.46     183.38  25,711,900\n",
      "Jun 22, 2018  186.12  186.15  184.70  184.92     182.85  27,200,400\n",
      "Jun 25, 2018  183.40  184.92  180.73  182.17     180.13  31,663,100\n",
      "Jun 26, 2018  182.99  186.53  182.54  184.43     182.36  24,569,200\n",
      "Jun 27, 2018  185.23  187.28  184.03  184.16     182.10  25,285,300\n",
      "Jun 28, 2018  184.10  186.21  183.80  185.50     183.42  17,365,200\n",
      "Jun 29, 2018  186.29  187.19  182.91  185.11     183.04  22,737,700\n",
      "Jul 02, 2018  183.82  187.30  183.42  187.18     185.08  17,731,300\n",
      "Jul 03, 2018  187.79  187.95  183.54  183.92     181.86  13,954,800\n",
      "Jul 05, 2018  185.26  186.41  184.28  185.40     183.32  16,604,200\n",
      "Jul 06, 2018  185.42  188.43  185.20  187.97     185.86  17,485,200\n",
      "Jul 09, 2018  189.50  190.68  189.30  190.58     188.45  19,756,600\n",
      "Jul 10, 2018  190.71  191.28  190.18  190.35     188.22  15,939,100\n",
      "Jul 11, 2018  188.50  189.78  187.61  187.88     185.78  18,831,500\n",
      "Jul 12, 2018  189.53  191.41  189.31  191.03     188.89  18,041,100\n",
      "Jul 13, 2018  191.08  191.84  190.90  191.33     189.19  12,513,900\n",
      "...              ...     ...     ...     ...        ...         ...\n",
      "Jan 08, 2019  149.56  151.82  148.52  150.75     150.11  41,025,300\n",
      "Jan 09, 2019  151.29  154.53  149.63  153.31     152.66  45,099,100\n",
      "Jan 10, 2019  152.50  153.97  150.86  153.80     153.14  35,780,700\n",
      "Jan 11, 2019  152.88  153.70  151.51  152.29     151.64  27,023,200\n",
      "Jan 14, 2019  150.85  151.27  149.22  150.00     149.36  32,439,200\n",
      "Jan 15, 2019  150.27  153.39  150.05  153.07     152.42  28,710,900\n",
      "Jan 16, 2019  153.08  155.88  153.00  154.94     154.28  30,569,700\n",
      "Jan 17, 2019  154.20  157.66  153.26  155.86     155.19  29,821,200\n",
      "Jan 18, 2019  157.50  157.88  155.98  156.82     156.15  33,751,000\n",
      "Jan 22, 2019  156.41  156.73  152.62  153.30     152.65  30,394,000\n",
      "Jan 23, 2019  154.15  155.14  151.70  153.92     153.26  23,130,600\n",
      "Jan 24, 2019  154.11  154.48  151.74  152.70     152.05  25,441,500\n",
      "Jan 25, 2019  155.48  158.13  154.32  157.76     157.09  33,535,500\n",
      "Jan 28, 2019  155.79  156.33  153.66  156.30     155.63  26,192,100\n",
      "Jan 29, 2019  156.25  158.13  154.11  154.68     154.02  41,587,200\n",
      "Jan 30, 2019  163.25  166.15  160.23  165.25     164.54  61,109,800\n",
      "Jan 31, 2019  166.11  169.00  164.56  166.44     165.73  40,739,600\n",
      "Jan 31, 2019  166.11  169.00  164.56  166.44     165.73  40,739,600\n",
      "Feb 01, 2019  166.96  168.98  165.93  166.52     165.81  32,668,100\n",
      "Feb 04, 2019  167.41  171.66  167.28  171.25     170.52  31,495,500\n",
      "Feb 05, 2019  172.86  175.08  172.35  174.18     173.44  36,101,600\n",
      "Feb 06, 2019  174.65  175.57  172.85  174.24     173.50  28,239,600\n",
      "Feb 07, 2019  172.40  173.94  170.34  170.94     170.21  31,741,700\n",
      "Feb 08, 2019  168.99  170.66  168.42  170.41     170.41  23,820,000\n",
      "Feb 11, 2019  171.05  171.21  169.25  169.43     169.43  20,993,400\n",
      "Feb 12, 2019  170.10  171.00  169.70  170.89     170.89  22,283,500\n",
      "Feb 13, 2019  171.39  172.48  169.92  170.18     170.18  22,490,200\n",
      "Feb 14, 2019  169.71  171.26  169.38  170.80     170.80  21,835,700\n",
      "Feb 15, 2019  171.25  171.70  169.75  170.42     170.42  24,626,800\n",
      "Feb 19, 2019  169.71  171.44  169.49  170.93     170.93  18,972,800\n",
      "\n",
      "[183 rows x 6 columns]\n",
      "len of whole extracted data set = 183\n"
     ]
    }
   ],
   "source": [
    "## Try Scraping with APPL. \n",
    "\n",
    "# Initialize the end date to be today and start date is one year before. \n",
    "print(\"\")\n",
    "print(\"\")\n",
    "start_date = datetime.date(2018, 6, 2)\n",
    "end_date = datetime.date(2019, 2, 19)\n",
    "today = datetime.date.today()\n",
    " \n",
    "# The statements in this group are for debugging purposes only\n",
    "format_string='%Y-%m-%d %H:%M:%S'\n",
    "t1 = start_date.strftime(\"%Y-%m-%d 00:00:00\")\n",
    "t2 = end_date.strftime(\"%Y-%m-%d 00:00:00\")\n",
    "start_date_epoch = str(int(time.mktime(time.strptime(t1, format_string))))\n",
    "end_date_epoch = str(int(time.mktime(time.strptime(t2,format_string))))\n",
    " \n",
    "# Output all 'original' dates\n",
    "print('Today     :', today)\n",
    "print('Start Date:', start_date, 'Start Date Epoch:', start_date_epoch)\n",
    "print('End   Date:', end_date,   'End   Date Epoch:', end_date_epoch)\n",
    " \n",
    "# Initialize 'date1'\n",
    "date1 = start_date\n",
    " \n",
    "# Initialize 'date1'\n",
    "date1 = start_date\n",
    " \n",
    "# Do not allow the 'End Date' to be AFTER today\n",
    "if today < end_date:\n",
    "    end_date = today\n",
    "\n",
    "iteration_number = 0\n",
    "while date1 <= end_date:\n",
    "    iteration_number += 1\n",
    " \n",
    "    # Create 'date2' in a 60 day Window or less\n",
    "    date2 = date1 + monthdelta.monthdelta(2)\n",
    "    date2 = datetime.date(date2.year, date2.month, 1)\n",
    "    date2 = date2 - datetime.timedelta(days=1)\n",
    "         \n",
    "    # Do not allow 'date2' to go beyond the 'End Date'\n",
    "    if date2 > end_date:\n",
    "        date2 = end_date\n",
    "         \n",
    "    print(f\"Processing {date1} thru {date2}.\")\n",
    "    stock_symbol = 'AAPL'\n",
    "    df = get_historical_price(stock_symbol, date1, date2)\n",
    "     \n",
    "    if iteration_number == 1:\n",
    "        dfall = df.copy()\n",
    "    else:\n",
    "        frames = [dfall, df]\n",
    "        dfall = pd.concat(frames)\n",
    " \n",
    "    # # # print(dfall)\n",
    "    # # # print(\"len of dfall = {}\".format(len(dfall)))\n",
    " \n",
    "    # Increment the first date for the next pass\n",
    "    date1 = date1   + monthdelta.monthdelta(2)\n",
    "    date1 = datetime.date(date1.year, date1.month, 1)\n",
    "\n",
    "# Output concatenated data set\n",
    "print(dfall)\n",
    "print(f\"len of whole extracted data set = {len(dfall)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Web Scraping with Short and Long Term Bond ETFs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to scrape long term data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_long_historical_price(ticker, start_date, end_date, frequency='1d',display=True):\n",
    "\n",
    "    date1 = start_date\n",
    "    iteration_number = 1\n",
    "\n",
    "    dfall = {}\n",
    "    \n",
    "    while date1 <= end_date:\n",
    "\n",
    "        if frequency == '1d':      \n",
    "            month_delta = 3         \n",
    "        else:          \n",
    "            if frequency == '1wk':            \n",
    "                month_delta = 12            \n",
    "            else:            \n",
    "                month_delta = 48\n",
    "                                \n",
    "        # Create 'date2' in a 60 day Window or less\n",
    "        date2 = date1 + monthdelta.monthdelta(month_delta)\n",
    "        date2 = datetime.date(date2.year, date2.month, 1)\n",
    "        date2 = date2 - datetime.timedelta(days = 1)\n",
    "\n",
    "        # Do not allow 'date2' to go beyond the 'End Date'\n",
    "        if date2 > end_date:\n",
    "            date2 = end_date\n",
    "            \n",
    "        # print(f\"Processing {date1} thru {date2}.\")\n",
    "\n",
    "        try: \n",
    "        \n",
    "            df = get_historical_price(ticker, date1, date2, frequency, display)  \n",
    "\n",
    "            if len(df) > 0: \n",
    "                \n",
    "                if iteration_number == 1:\n",
    "                    dfall = df.copy()\n",
    "                else:\n",
    "                    frames = [dfall, df]\n",
    "                    dfall = pd.concat(frames) \n",
    "\n",
    "                iteration_number += 1 \n",
    "                \n",
    "            date1 = date1 + monthdelta.monthdelta(month_delta)\n",
    "            date1 = datetime.date(date1.year, date1.month, 1)\n",
    "            \n",
    "        except:\n",
    "            \n",
    "            date1 = date1 + monthdelta.monthdelta(month_delta)\n",
    "            date1 = datetime.date(date1.year, date1.month, 1)\n",
    "            \n",
    "    return dfall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ETF Tickers\n",
    "* Long Term Bond ETFs:\n",
    "    * IEF --> iShares Barclays 7-10 Year Trasry Bnd Fd\n",
    "    * DTYL --> BARCLAY BK IPAT US TR 10 YR BULL ETN\n",
    "    * EDV --> VANGUARD WORLD/EXTD DURATION TREAS\n",
    "    * TLH --> iShares 10-20 Year Treasury Bond ETF\n",
    "* Long Term Bond ETFs:\n",
    "    * SHV --> iShares Short Treasury Bond ETF \n",
    "    * VGSH --> Vanguard Short-Term Treasury ETF\n",
    "    * SCHR --> Schwab Intermediate-Term US Trs ETF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "Short_TR_Tickers = ['IEF','DTYL','EDV','TLH']\n",
    "Long_TR_Tickers = ['SHV','VGSH','SCHR']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loop through each ticker to scrape data, Scrape from 2000 to today.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Scraping ticker is IEF\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:37: FutureWarning: convert_objects is deprecated.  To re-infer data dtypes for object columns, use DataFrame.infer_objects()\n",
      "For all other conversions use the data-type specific converters pd.to_datetime, pd.to_timedelta and pd.to_numeric.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully Scraping historical data from  Jul 30, 2002  to  Feb 22, 2019\n",
      "Number of data extracted = 4219\n",
      "\n",
      "\n",
      "Scraping ticker is DTYL\n",
      "Successfully Scraping historical data from  Aug 11, 2010  to  Jan 30, 2019\n",
      "Number of data extracted = 430\n",
      "\n",
      "\n",
      "Scraping ticker is EDV\n",
      "Successfully Scraping historical data from  Jan 31, 2008  to  Feb 22, 2019\n",
      "Number of data extracted = 2633\n",
      "\n",
      "\n",
      "Scraping ticker is TLH\n",
      "Successfully Scraping historical data from  Jan 12, 2007  to  Feb 22, 2019\n",
      "Number of data extracted = 2854\n"
     ]
    }
   ],
   "source": [
    "# Scrape Short Term Bonds\n",
    "Short_TR_Data_Dict = {}\n",
    "\n",
    "for ticker in Short_TR_Tickers:\n",
    "    \n",
    "    # Set up start and end date\n",
    "    start_date = datetime.date(2000, 1, 2)\n",
    "    end_date = datetime.date.today()\n",
    "    \n",
    "    print(\"\")\n",
    "    print(\"\")\n",
    "    print (f'Scraping ticker is {ticker}')\n",
    "   \n",
    "    ticker_df = get_long_historical_price(ticker, start_date, end_date, '1d', False)\n",
    "    \n",
    "    print ('Successfully Scraping historical data from ',ticker_df.index[0],' to ',ticker_df.index[-1])\n",
    "    print (f'Number of data extracted = {len(ticker_df)}')\n",
    "    \n",
    "    Short_TR_Data_Dict = {**Short_TR_Data_Dict,**{ticker:ticker_df}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Scraping ticker is SHV\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:37: FutureWarning: convert_objects is deprecated.  To re-infer data dtypes for object columns, use DataFrame.infer_objects()\n",
      "For all other conversions use the data-type specific converters pd.to_datetime, pd.to_timedelta and pd.to_numeric.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully Scraping historical data from  Jan 11, 2007  to  Feb 22, 2019\n",
      "Number of data extracted = 3030\n",
      "\n",
      "\n",
      "Scraping ticker is VGSH\n",
      "Successfully Scraping historical data from  Dec 31, 2009  to  Feb 22, 2019\n",
      "Number of data extracted = 2201\n",
      "\n",
      "\n",
      "Scraping ticker is SCHR\n",
      "Successfully Scraping historical data from  Aug 05, 2010  to  Feb 22, 2019\n",
      "Number of data extracted = 2174\n"
     ]
    }
   ],
   "source": [
    "# Scrape Short Term Bonds\n",
    "Long_TR_Data_Dict = {}\n",
    "\n",
    "for ticker in Long_TR_Tickers:\n",
    "    \n",
    "    # Set up start and end date\n",
    "    start_date = datetime.date(2000, 1, 2)\n",
    "    end_date = datetime.date.today()\n",
    "    \n",
    "    print(\"\")\n",
    "    print(\"\")\n",
    "    print (f'Scraping ticker is {ticker}')\n",
    "   \n",
    "    ticker_df = get_long_historical_price(ticker, start_date, end_date, '1d', False)\n",
    "    \n",
    "    print ('Successfully Scraping historical data from ',ticker_df.index[0],' to ',ticker_df.index[-1])\n",
    "    print (f'Number of data extracted = {len(ticker_df)}')\n",
    "    \n",
    "    Long_TR_Data_Dict = {**Long_TR_Data_Dict,**{ticker:ticker_df}}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AGGREGATE DATA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aggregate and Clean Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_Data_Dict = {**Short_TR_Data_Dict,**Long_TR_Data_Dict}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Jan 11, 2007</th>\n",
       "      <td>108.70</td>\n",
       "      <td>108.70</td>\n",
       "      <td>108.70</td>\n",
       "      <td>108.70</td>\n",
       "      <td>98.78</td>\n",
       "      <td>900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Jan 16, 2007</th>\n",
       "      <td>108.76</td>\n",
       "      <td>108.76</td>\n",
       "      <td>108.74</td>\n",
       "      <td>108.74</td>\n",
       "      <td>98.81</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Apr 02, 2007</th>\n",
       "      <td>108.99</td>\n",
       "      <td>109.03</td>\n",
       "      <td>108.91</td>\n",
       "      <td>109.00</td>\n",
       "      <td>99.83</td>\n",
       "      <td>23,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Apr 03, 2007</th>\n",
       "      <td>109.05</td>\n",
       "      <td>109.07</td>\n",
       "      <td>108.98</td>\n",
       "      <td>109.02</td>\n",
       "      <td>99.85</td>\n",
       "      <td>25,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Apr 04, 2007</th>\n",
       "      <td>109.07</td>\n",
       "      <td>109.11</td>\n",
       "      <td>109.06</td>\n",
       "      <td>109.08</td>\n",
       "      <td>99.90</td>\n",
       "      <td>20,800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Open    High     Low   Close  Adj Close  Volume\n",
       "Date                                                           \n",
       "Jan 11, 2007  108.70  108.70  108.70  108.70      98.78     900\n",
       "Jan 16, 2007  108.76  108.76  108.74  108.74      98.81     500\n",
       "Apr 02, 2007  108.99  109.03  108.91  109.00      99.83  23,000\n",
       "Apr 03, 2007  109.05  109.07  108.98  109.02      99.85  25,000\n",
       "Apr 04, 2007  109.07  109.11  109.06  109.08      99.90  20,800"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_Data_Dict['SHV'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Go Through each table and do the followings:\n",
    "1) Adjust column names to replace space with _\n",
    "2) Change all the data from string to float\n",
    "3) Add extra column with the ticker name\n",
    "4) Change the date string to datetime object\n",
    "'''\n",
    "for key,table in total_Data_Dict.items():\n",
    "    table.rename(columns={'Adj Close':'Adj_Close'},inplace=True)\n",
    "    table_name = table.columns\n",
    "    for name in table_name:\n",
    "        table[name] = table[name].apply(lambda x: float(x.replace(',','').replace('-','0')) if isinstance(x,str) else x)\n",
    "    table = table.reset_index()\n",
    "    table['Ticker'] = key\n",
    "    table['Date'] = table['Date'].apply(lambda x: datetime.datetime.strptime(x,'%b %d, %Y').date())\n",
    "    total_Data_Dict[key] = table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj_Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Ticker</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2007-01-11</td>\n",
       "      <td>108.70</td>\n",
       "      <td>108.70</td>\n",
       "      <td>108.70</td>\n",
       "      <td>108.70</td>\n",
       "      <td>98.78</td>\n",
       "      <td>900.0</td>\n",
       "      <td>SHV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2007-01-16</td>\n",
       "      <td>108.76</td>\n",
       "      <td>108.76</td>\n",
       "      <td>108.74</td>\n",
       "      <td>108.74</td>\n",
       "      <td>98.81</td>\n",
       "      <td>500.0</td>\n",
       "      <td>SHV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2007-04-02</td>\n",
       "      <td>108.99</td>\n",
       "      <td>109.03</td>\n",
       "      <td>108.91</td>\n",
       "      <td>109.00</td>\n",
       "      <td>99.83</td>\n",
       "      <td>23000.0</td>\n",
       "      <td>SHV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2007-04-03</td>\n",
       "      <td>109.05</td>\n",
       "      <td>109.07</td>\n",
       "      <td>108.98</td>\n",
       "      <td>109.02</td>\n",
       "      <td>99.85</td>\n",
       "      <td>25000.0</td>\n",
       "      <td>SHV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2007-04-04</td>\n",
       "      <td>109.07</td>\n",
       "      <td>109.11</td>\n",
       "      <td>109.06</td>\n",
       "      <td>109.08</td>\n",
       "      <td>99.90</td>\n",
       "      <td>20800.0</td>\n",
       "      <td>SHV</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date    Open    High     Low   Close  Adj_Close   Volume Ticker\n",
       "0  2007-01-11  108.70  108.70  108.70  108.70      98.78    900.0    SHV\n",
       "1  2007-01-16  108.76  108.76  108.74  108.74      98.81    500.0    SHV\n",
       "2  2007-04-02  108.99  109.03  108.91  109.00      99.83  23000.0    SHV\n",
       "3  2007-04-03  109.05  109.07  108.98  109.02      99.85  25000.0    SHV\n",
       "4  2007-04-04  109.07  109.11  109.06  109.08      99.90  20800.0    SHV"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the cleaned up date\n",
    "total_Data_Dict['SHV'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The aggregated table has data = 17541\n"
     ]
    }
   ],
   "source": [
    "# Aggregate all the tables\n",
    "iteration = 1\n",
    "for key,table in total_Data_Dict.items():\n",
    "    if iteration == 1:\n",
    "        agg_table = table.copy()\n",
    "    else:\n",
    "        agg_table = pd.concat([agg_table,table],ignore_index=True)\n",
    "    iteration += 1\n",
    "    \n",
    "agg_table.index.name = 'id'\n",
    "agg_table.index += 1\n",
    "    \n",
    "print(f'The aggregated table has data = {len(agg_table)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Data to SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy.ext.declarative import declarative_base\n",
    "Base = declarative_base()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "connection_string = \"root:\"+sql_Password+\"@localhost/ETL_db\"\n",
    "engine = create_engine(f'mysql://{connection_string}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Yield Curve Class\n",
    "class ETF_Data(Base):\n",
    "    __tablename__ = 'ETF_Data'\n",
    "    __table_args__ = {'extend_existing': True} \n",
    "    id = Column(Integer, primary_key=True)\n",
    "    Ticker = Column(String(5))\n",
    "    Date = Column(Date)\n",
    "    Open = Column(Float)\n",
    "    High = Column(Float)\n",
    "    Low = Column(Float)  \n",
    "    Close = Column(Float) \n",
    "    Adj_Close = Column(Float)\n",
    "    Volume = Column(Float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "Base.metadata.create_all(engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_table.to_sql(name='ETF_Data', con=engine, if_exists='append', index=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
